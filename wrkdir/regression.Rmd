---
title: "Assignment 3"
output: html_notebook
---

1. (1p) Download the dataset college.csv and explore its overall structure. Get a summary statistics of each
variable. Answer the following questions:
• How many observation do you have in the data?
• How many categorical and numeric variables you have in your data?

```{r}
clg_df = read.csv("College.csv")
str(clg_df)
```

There are 777 observations, 2 categorical variables and 17 numeric variables.

• Is there any missing value?
```{r}
sum(is.na(clg_df))
```
There appear to be no missing values in the dataset

2. (1pt) Remove the first column (the name of the college)
```{r}
clg_df = clg_df[,-1]
```

3. (2 pts) Which variables are associated with “Apps”. Use “pairs”, “cor”, and side by side box plot with
t.test to answer this question.

```{r}
clg_df = as.data.frame(unclass(clg_df), stringsAsFactors = TRUE)
attach(clg_df)
```
Converting strings to factors and attaching the dataframe
```{r}
iqr = 3264 - 776
iqr_index = (Apps > 776 - 1.5*iqr & Apps < 3264 + 1.5*iqr)
Apps_so = Apps[iqr_index] #so means sans outliers
Private_so = Private[iqr_index]
plot(Apps_so~Private_so)
t.test(Apps_so~Private_so)
```
```{r}
pairs(clg_df[2:6])
pairs(clg_df[c(2,7:9)])
pairs(clg_df[c(2,10:12)])
pairs(clg_df[c(2,13:15)])
pairs(clg_df[c(2,16:18)])
```

```{r}
cor(Apps, clg_df[ ,-c(1, 2)])
```

From the above tests I've concluded that Accept, Enroll, F.Undergrad, Private, Top25perc, P.Undergrad, Outstate, PhD, and Terminal are mildly to highly associated with Apps

4. (1pt) plot the histogram of the number of applications “Apps” variable. Explain what the histogram shows?
```{r}
hist(Apps)
```

Judging from the shape this historgram is right-skewed (possibly j-shaped if you see the small hump between 45k and 50k) with a mean between 0 and 10000

5. (1pt) replace the “Top10perc” variable with a factor variable “Elite” with two levels: “Yes” if 50% or more of new students coming from the top 10% of their high school class (that is, if Top10Perc>=50) , and “No” if less than 50% of new students are coming from the top10% of their high school class.

```{r}
clg_df$Elite = factor(ifelse(clg_df$Top10perc >= 50, "Yes", "No"))
clg_df = clg_df[-5]
```

6. (1pt) is the Elite variable you created above associated with the “Apps” variable? Don’t just say yes or no, you should explain your answer by plots and test statistics.

```{r}
Elite_so = clg_df$Elite[iqr_index]
plot(Apps_so~Elite_so)
t.test(Apps_so~Elite_so)
```

Based on the side-by-side box plot and the p-value = 0.01% < 5% it follows that Elite is associated with Apps

7. (1pt) normalize all numerical features (except the “Apps” variable) using z-score standardization using “scale” function
```{r}
clg_norm = as.data.frame(scale(clg_df[-c(1,2,18)], center=TRUE, scale=TRUE))
clg_norm$Private = clg_df$Private
clg_norm$Apps = clg_df$Apps
clg_norm$Elite = clg_df$Elite
```

8. set the random seed: set.seed(123)
```{r}
set.seed(123)
```

9. (2 pt) Use caret package to run 10 fold cross validation using linear regression method on all features.

Print the resulting model to see the cross validation RMSE. 
In addition, take a summary of the model and interpret the coefficients. 
Which coefficients are statistically different from zero? What does this meant?
```{r}
#install caret package and use the library
install.packages("caret")
library(caret)
```
```{r}
train.control = trainControl(method = "cv", number = 10)
model = train(Apps ~ ., data = clg_norm, method = "lm", trControl = train.control)
```
```{r}
model
summary(model)
```
According to the p-test [Pr(>|t|)] results Accept, Enroll, and EliteYes are statistically different from zero, which means that the true values for these coefficients are unlikely to be zero

10. Set the random seed again. We need to do this before each training to ensure we get the same folds in cross validation. Set.seed(123) so we can compare the models using their cross validation RMSE.
```{r}
set.seed(123)
```

11. (3 pts) Use caret and leap packages to run a 10 fold cross validation using step wise linear regression method with backward selection (i.e., method=”leapBackward). The train method by default uses maximum of 4 predictors and reports the best models with 1..4 predictors. We need to change this parameter to consider 1..16 predictors. So inside your train function, add the following parameter tuneGrid = data.frame(nvmax = 1:16) . Which model (with how many variables or nvmax ) has the lowest RMSE. Take the summary of the final model to see which variables are selected in the model with the lowest RMSE?

```{r}
train.control = trainControl(method = "cv", number = 10)
step.model = train(Apps ~ ., data = clg_norm, method = "leapBackward", trControl = train.control, tuneGrid = data.frame(nvmax = 1:16))
```
```{r}
step.model
summary(step.model$finalModel)
```
Accept, Expend, and EliteYes were selected


